---
title: 🧠 DeepSeek Engram：AI 内存架构的范式转移
date: 2026-02-15 12:00:00
tags:
  - DeepSeek
  - AI架构
  - HBM
  - 内存层级
  - 投资分析
  - 半导体
categories:
  - 技术探索
---

## 引言：2.8% 的震撼

**2.8%**。

这不是 benchmark 分数，而是一张收据。

DeepSeek 最新论文展示了一个惊人的结果：他们把 1000 亿参数的"记忆表"放在普通服务器 DRAM 里（不是昂贵的 HBM），而吞吐量损失**仅 2.8%**。

过去 18 个月，AI 基础设施领域有一条不成文的规则：**交 HBM 税，否则别想上桌**。这篇论文没有说"HBM 已死"，而是问了一个更危险的问题：

**如果我们不必为所有东西交税呢？**

---

## 一、"爱因斯坦问题"：为什么我们在浪费硅

### 现状的荒谬

现代 LLM 把大量计算浪费在"重建"静态内容上：
- 人名
- 惯用语
- 模板化短语
- 可预测的语法结构

这就像**雇爱因斯坦来背乘法表**——这不是智能，这是资本毁灭。

### Engram 的核心洞见

**停止让模型"思考"静态事实，让它去查找。**

- GPU 大脑 → 用于推理
- 内存 → 用于事实

---

## 二、概念澄清：MoE vs Engram

投资界经常混淆这两个概念，但它们是正交的：

| 概念 | 含义 | 类比 |
|------|------|------|
| **MoE** (Mixture-of-Experts) | 稀疏计算 | 不唤醒整个大脑，只唤醒几个"专家" |
| **Engram** | 稀疏内存 | 把静态模式存在表里，不用每次重新计算 |

**哲学转变**：内存不再是 hack，而是**设计原则**。

### 关键实验结果

论文做了"预算重分配"实验，发现最佳点：

> 把约 **20%-25%** 的稀疏预算从专家转移到内存，性能反而提升。

这意味着未来的前沿模型将有一个真正的"内存分配"决策——就像数据中心有"电力分配"决策一样。

---

## 三、被忽视的事实：不仅更便宜，还更好

大多数效率故事都有小字条款：省钱但降质。

**Engram 相反**。

### 质量提升

分离"计算"和"内存"后：
- 模型分数**上升**，而非下降
- 在**通用推理**和**代码/数学**任务上提升明显
- 不只是知识类任务

### 长上下文优势

32k token 长上下文扩展实验中：
- Engram 在长距离检索和推理基准上**超越 MoE 基线**

**原因很清晰**：
- 把局部、重复的模式 offload 到 lookup
- 停止在"闲聊"上浪费注意力预算
- 保留容量给全局上下文

**这不是"降本"功能，而是让长上下文更便宜、更好的新架构。**

---

## 四、硬件冲击：HBM 不再是唯一的王

### 为什么 2.8% 很重要

**确定性 lookup 让延迟可隐藏。**

Engram 的 lookup 是**确定性的**——系统在层执行前就知道需要什么。因此可以**预取**：在 GPU 忙别的时候，后台提前拉数据。

**技巧**：把内存传输和计算重叠，而不是让 GPU 空等。

论文强调这是**保守基线**——他们强制从 host memory 走 PCIe。即使如此，惩罚仍然很小。

### 分层内存成为新常态

这不会杀死 HBM，而是**重新定义**它：

| 层级 | 类比 | 用途 | 速度 | 成本 |
|------|------|------|------|------|
| **HBM** | 剪贴板 | 极快极小，放"热"工作集 | 最快 | 最贵 |
| **DRAM** | 桌面 | 大、便宜、较慢，放"温"库 | 中等 | 中等 |
| **SSD (NVMe)** | 文件柜 | 巨大、最便宜、最慢，放"冷"长尾 | 慢 | 最低 |

论文明确指向**多级缓存层级**：
- 高频项 → 更快层级（HBM/DRAM）
- 长尾 → 住在 NVMe SSD

**关键信息**：不是"HBM 无用"，而是"HBM 不再是唯一能承载规模的地方"。

---

## 五、买方现实：供应弹性决定谁赚钱

这部分区分投资者和工程师。

### HBM：结构性稀缺

不只是晶圆。还有：
- 堆叠
- 封装
- 良率
- 响应缓慢的供应链

**溢价可以持续**。

但论文审计了"无限 HBM 需求"的故事——**斜率现在很重要**。

### DRAM：窗口交易

如果这种架构成为主流，每台服务器的 DRAM 上升 → **利好销量**。

但 DRAM 更容易扩产。当利润飙升，供应会涌入。

**好交易，但很少是永远的投资**。

### SSD (NAND)：仍然是周期

Engram 把 NVMe SSD 拉进推理路径是**重大地位升级**。

但 NAND 仍然是价格战生意。技术不能消除周期，只是改变周期何时咬人。

---

## 六、二阶交易："道路"

如果更多内存放在 GPU 外，瓶颈就从**存储**转向**移动数据**。

PCIe 今天看起来很无聊。在这个世界里，**PCIe 和 CXL 开始像高速公路**。

**如果不想为 HBM 容量付费，你就要为带宽付费。**

---

## 七、投资启示：效率是新的 Alpha

### 核心论点

这篇论文不是"研究内容"，而是**摊牌**。

DeepSeek 不是想靠"聪明 5%"赢。他们想靠**结构性更低的成本基础**赢。

### 交易框架的转变

**停止交易"更聪明的模型"。**

**开始交易推理成本曲线。**

因为一旦成本崩溃，采用就不再是 demo，而是**现金流事件**。

### 关键结论

| 资产 | 观点 |
|------|------|
| **HBM** | 保持为王，但失去对容量的垄断 |
| **DRAM/NAND** | 获得销量超级周期，但警惕供应洪水 |
| **PCIe/CXL** | 从 boring spec 变成关键基础设施 |
| **效率** | 新的 Alpha |

---

## 结语：范式转移的时刻

Engram 代表的不是渐进式改进，而是**架构范式的转移**。

它挑战了 AI 硬件领域最核心的假设：**规模必须等于 HBM**。

如果 DeepSeek 的路径被验证：
- 训练和推理成本可能下降一个数量级
- 小型玩家可以用普通硬件挑战巨头
- AI 采用的门槛大幅降低
- 整个半导体供应链重新定价

这不是说 HBM 会消失。它是说，**AI 的内存架构将变得像计算机科学的其他部分一样——分层、缓存、智能调度**。

在 2023-2024 年，我们学到了"算力即权力"。

在 2025-2026 年，我们可能要学习：**效率即权力**。

---

## 参考

- DeepSeek Engram 论文
- Original analysis by @Tigris
- USGS Mineral Commodity Summaries

---

*本文基于 @tig88411109 的技术分析推文整理。*  
*投资有风险，半导体行业周期性强，请谨慎决策。*
