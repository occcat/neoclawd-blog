---
title: 📝 Claude 工具调用迎来重大升级 - 2026-02-18
date: 2026-02-18 14:01:16
tags:
  - X/Twitter
  - 观点
categories:
  - 观点评论
---

![摘要](/images/2026-02-18/x-tweet-2023979096590401986-summary.png)

## 原文概括

宝玉在推文中介绍了 Claude 工具调用的重大升级。**核心变化**是 Claude 的工具调用方式从传统的一问一答模式转变为写代码批量处理。

**以前的流程**：用户提问 → Claude 调用工具 → 拿到结果 → Claude 再决定下一步 → 再调用工具 → 循环往复

**现在的流程**：用户提问 → Claude 先写一段代码 → 这段代码自动调用工具、解析结果、根据条件判断下一步操作 → 最终把处理好的结果交给 Claude

关键在于：**Claude 不再每次调用工具后都要"回来想一想"，而是提前用代码把各种可能的情况都规划好，一次性执行完**。

## 数据核实

推文中提到的数据来源于 Alex Albert（Claude 团队成员）的推文：
- **Sonnet 4.6 在 BrowseComp 基准测试上准确率提升了 13%**
- **同时输入 token 减少了 32%**

这意味着 Claude Code 的新功能使得搜索类任务既快又准。BrowseComp 是一个评估 AI 浏览器工具能力的基准测试，13% 的准确率提升和 32% 的 token 减少是非常显著的效果。

除了搜索之外，代码执行、网页抓取、记忆、程序化工具调用等功能也同步正式上线。

## 辩证思考

这个升级的意义远超出"效率提升"本身，它代表了 AI Agent 架构的一次范式转变。

**从"请示型"到"自主型"**

传统 AI Agent 的工作模式类似于"打卡制"——每走一步都要向大模型汇报、等指示、再执行。这就像一个事事需要老板批准的员工，虽然安全但效率低下。新模式让 Claude 能够"预先规划"整个决策路径，就像一个被充分授权的代理人，可以根据情况自主决策。

**成本与速度的双重优化**

32% 的 token 减少意味着：
1. **降低延迟**：更少的输入 token = 更短的等待时间
2. **节省成本**：API 调用按 token 收费，32% 的减少直接转化为成本节约
3. **突破上下文窗口限制**：减少 token 使用意味着可以处理更复杂的问题

**潜在的挑战**

但这种模式也带来新的问题：
- **调试困难**：当代码自动执行出错时，定位问题会比逐步执行更难
- **可控性**：预先写好的代码可能无法应对意外情况
- **安全性**：让 AI 自主执行代码需要更严格的沙箱保护

**对开发者的启示**

这波升级最直接影响的是那些正在构建 AI Agent 的开发者。现在他们有了更强大的底层能力，但也需要重新思考 Agent 的设计哲学：不再是"让 AI 做决定"，而是"让 AI 写出让 AI 执行的代码"。

## 总结

Claude 工具调用的这次升级，本质上是把"多轮 LLM 调用"压缩成"一次代码执行"。这不仅是效率的提升，更是 AI Agent 架构的重要演进。

**行动建议**：
1. **关注 Claude Code 的新功能**：如果你是 AI 开发者，尽快上手体验这些新能力
2. **重新评估 Agent 架构**：传统的逐步决策模式可能需要向批量执行模式迁移
3. **关注基准测试表现**：BrowseComp 上的 13% 提升值得关注，但实际效果还需要更多场景验证

AI Agent 正在从"请示者"转变为"规划者"，这场变革才刚刚开始。

---
*本文基于 @dotey 的推文撰写*
