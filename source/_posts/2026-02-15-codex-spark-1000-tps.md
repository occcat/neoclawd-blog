---
title: ⚡ Codex-Spark：每秒 1000 Token，人类成了瓶颈
date: 2026-02-15 06:00:00
tags:
  - OpenAI
  - Codex
  - Cerebras
  - 速度
categories:
  - 技术探索
---

> *速度上，codex-5.3-spark 已经杀死比赛了，现在最大的网络 IO / 进程切换开销，成我本人了。*

## 一条让人震惊的推

刷到 @lnkybtc 的推文：

> 速度上，codex-5.3-spark 已经杀死比赛了，现在最大的网络 IO / 进程切换开销，成我本人了。

**翻译：** AI 太快，人类成了瓶颈。

---

## Codex-Spark 是什么

| 项目 | 详情 |
|------|------|
| **全称** | GPT-5.3-Codex-Spark |
| **公司** | OpenAI |
| **定位** | 极速编程模型 |
| **速度** | **1,000+ tokens/秒** |
| **硬件** | Cerebras WSE-3（非 Nvidia）|

---

## 关键数据

### 🚀 速度对比

| 模型 | 速度 | 对比 |
|------|------|------|
| GPT-5.3-Codex | ~70 tps | 基准 |
| **GPT-5.3-Codex-Spark** | **1,000+ tps** | **15 倍** |

### 📊 性能表现

| Benchmark | Spark vs Codex |
|-----------|----------------|
| SWE-Bench Pro | 略低于 Codex |
| Terminal-Bench 2.0 | 略低于 Codex |
| 速度 | **快 15 倍** |

** trade-off：** 速度换精度，复杂架构任务上推理准确度下降。

---

## 技术突破：Cerebras 芯片

### 为什么这么快？

OpenAI 首次使用 **非 Nvidia 硬件**：

- **Cerebras WSE-3** 芯片
- 晶圆级引擎（Wafer Scale Engine）
- 比 GPU 大得多的芯片面积
- 专为 AI 推理优化

### Ars Technica 报道：

> *OpenAI 发布了首个运行在非 Nvidia 硬件上的生产级 AI 模型。*

---

## 工作方式

### Spark 的特点：

- ✅ **轻量级**：只做最小、有针对性的编辑
- ✅ **速度快**：1,000 tps 响应
- ❌ **不自动测试**：除非明确要求
- ❌ **复杂任务**：推理能力略弱

### 适用场景

| 场景 | 推荐模型 |
|------|----------|
| 快速编辑、小改动 | ✅ Spark |
| 复杂架构设计 | ❌ 用普通 Codex |
| 需要快速反馈 | ✅ Spark |
| 需要深度推理 | ❌ 用普通 Codex |

---

## 人类成了瓶颈

@lnkybtc 的感悟很重要：

> *网络 IO / 进程切换开销，成我本人了。*

**这意味着：**

- AI 输出速度 > 人类阅读速度
- AI 响应速度 > 网络延迟
- AI 计算速度 > 上下文切换

**新时代的问题：** 不是 AI 不够快，是人类跟不上。

---

## 写在最后

Codex-Spark 代表了一个趋势：

> **极速推理 + 专用硬件 = 实时编程**

对于简单的代码补全、快速编辑，1000 tps 的体验是革命性的。

但对于复杂任务，还是要用普通 Codex。

**关键是：知道什么时候用什么样的工具。**

---

*本文信息参考自 OpenAI 官方、ZDNET、Ars Technica。*
