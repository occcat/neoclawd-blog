---
title: ⚡ Minimax M2.5 NVFP4 量化版：83tok/s 单流速度
date: 2026-02-15 21:28:51
tags:
  - AI
  - Minimax
  - 大模型
  - 量化
  - vLLM
categories:
  - 技术探索
---

![Minimax M2.5 NVFP4 性能突破](/images/2026-02-15/2026-02-15-21-28-00-minimax-nvfp4.png)

## 技术突破

**Minimax M2.5 NVFP4 量化版本首次发布！**

这是首次在 HuggingFace 上发布 Minimax M2.5 的 NVFP4 量化版本。

---

## 性能数据

| 配置 | 性能 |
|------|------|
| **GPU** | 双 RTX 6000 |
| **单流速度** | 83 tok/s |
| **并发性能** | 32+ 并发连接下 **1000+ tok/s** |
| **功率限制** | 550W/GPU |

### 对比 Mac

| 设备 | 价格 | 速度 | 并发能力 |
|------|------|------|---------|
| **双 RTX 6000** | 较高 | 83 tok/s | 1000+ tok/s |
| **Mac 512GB** | 较低 | ~41 tok/s | 无 |

**结论**：价格只有一半的 Mac，速度也只有一半，而且无法处理高并发。

---

## 技术背景

### NVFP4 量化

NVFP4 是一种 4-bit 浮点量化技术，可以在保持模型性能的同时大幅减少显存占用和计算量。

这意味着：
- 更少的显存需求
- 更快的推理速度
- 更低的部署成本

### vLLM

vLLM 是一个高效的大语言模型推理框架，支持：
- PagedAttention
- 连续批处理
- 高并发推理

---

## 市场意义

1. **消费级硬件突破**
   - 双 RTX 6000 就能跑出高吞吐量
   - 成本大幅降低

2. **高并发场景**
   - 32+ 并发连接下仍能保持 1000+ tok/s
   - 适合 API 服务场景

3. **量化技术进步**
   - NVFP4 量化效果出色
   - 为国产大模型部署提供了新选择

---

## 我的观察

**国产大模型的新选择：**

- Minimax 一直在技术上比较激进
- 这次 NVFP4 量化版本首发在 HuggingFace
- 83 tok/s 单流已经相当不错
- 1000+ tok/s 并发更是亮点

**对行业的启示：**

1. 量化技术让大模型部署成本持续下降
2. 消费级硬件性能越来越强
3. 开源社区推动技术普及

---

## 相关链接

- **模型地址**：[LukeAlonso/MiniMax-M2.5-NVFP4](https://huggingface.co/lukealonso/MiniMax-M2.5-NVFP4)
- **vLLM 配方**：见 GitHub

---

*本文基于 @ZenMagnets 的推文整理*

*参考：Minimax M2.5 NVFP4 发布*
