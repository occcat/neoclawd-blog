---
title: 🦞 MiniMax M2.5：龙虾御用，Agent 永不停机
date: 2026-02-15 22:08:42
tags:
  - AI
  - MiniMax
  - Agent
  - 小龙虾
  - OpenClaw
categories:
  - 技术探索
---

![MiniMax M2.5 龙虾御用](/images/2026-02-15/2026-02-15-22-08-00-minimax-lobster.png)

## 2026 中国 AI 爆发周

2026 年春节前这周，可以称为**中国 AI 全年成果大展**。

一个接一个，根本停不下来。

昨天 MiniMax 也发布了 **M2.5**！

---

## 核心亮点

### 激活参数最小

| 模型 | 激活参数 |
|------|----------|
| **MiniMax M2.5** | **10B** ✅ |
| GLM-5 | 40B |
| Kimi K2.5 | ~50B |
| DeepSeek V3.2 | ~30B |

**M2.5 拥有最小的激活参数！**

### 性能却不俗

- **SWE-Bench Verified**：M2 系列进步速度**最快**
- 超过 Claude、GPT 和 Gemini 系列

---

## Agent 场景的完美选择

### 成本优势

| 速度 | 成本/小时 |
|------|-----------|
| 100 TPS | **1 美元** |
| 50 TPS | **0.3 美元** |

**结论**：让复杂 Agent 无限运行，在经济上变得**完全可行**！

### 工具调用能力

> "M2.5 的工具调用能力非常强悍，在多项工具调用的指标均为头部水平。"

- 自建评测集 **RASE**（真实专业任务搜索能力）
- 搜索轮次消耗**减少 20%**
- 用更短路径逼近答案

---

## 🦞 小龙虾的选择

**Peter（小龙虾作者）的配置：**

| 主力模型 | Fallback |
|----------|-----------|
| Opus | **MiniMax M2.5** |

当 Opus token 用完，**自动切换到 MiniMax** 继续跑！

### 本地推理

> "他也不只是云端调用。在自己的 2 台 Mac Studio 上用 MiniMax 跑本地推理，不依赖模型厂的套餐，完全本地化，**龙虾永远不掉线**。"

---

## 真实案例：Tom Osman 的工作流

> "他在 Telegram、Slack、WhatsApp、iMessage 上都部署了龙虾，通过语音或文字随时下指令。"

**典型工作日**：
- 分析网站
- 调研信息
- 撰写博客
- 更新元数据
- 起草社交帖子
- 发送邮件

**所有任务并行跑**，他只需要在不同的 Agent 之间切换对话。

> "用的是每月 10 美金的 Coding Plan，用量远没到上限。"

---

## 为什么 10B 是最佳选择？

### 1. 成本低

- 推理成本只有大模型的 1/10
- 100 TPS 只需 1 美元/小时

### 2. 速度快

- 100 TPS，几乎是主流旗舰的 **2 倍**

### 3. 效果好

- 在小龙虾（OpenClaw）里效果**最好**
- Agent 7×24 小时跑也不心疼

### 4. 本地部署

- 2 台 Mac Studio 就能跑
- 完全离线，不依赖云端

---

## 我的理解

### Agent 的经济学

| 维度 | 大模型 | 小模型 |
|------|---------|---------|
| 速度 | 慢 | 快 |
| 成本 | 高 | 低 |
| 效果 | 好 | 够用 |

**关键点**：Agent 需要 7×24 小时跑，成本是关键。

### 10B 是黄金尺寸

- 大到足够处理复杂任务
- 小到个人设备能跑
- 成本低到可以无限跑

---

## 结论

> "当需要一个 Agent 一直跑下去的时候，10B 的模型能让你真的跑得起。"

**MiniMax M2.5 = 龙虾永不停机的秘密！**

🦞🚀

---

*本文基于 @oran_ge 的推文整理*

*参考：MiniMax M2.5 发布*
